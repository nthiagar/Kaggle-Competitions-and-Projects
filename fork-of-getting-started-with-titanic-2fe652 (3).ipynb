{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport sklearn\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train= pd.read_csv(\"/kaggle/input/titanic/train.csv\")\ntest= pd.read_csv(\"/kaggle/input/titanic/test.csv\")\nx=test.PassengerId\ny=train.Survived","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import linear_model\nfrom sklearn import neighbors\nfrom sklearn.preprocessing import OneHotEncoder\nfrom xgboost import XGBClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"encoder = OneHotEncoder(sparse=False)\ntrain=train.drop(columns=['Cabin','PassengerId','Survived', 'Name'], axis=1)\ntest=test.drop(columns=['Cabin','PassengerId', 'Name'], axis=1)\ntrain['Age'].fillna((train['Age'].mean()), inplace=True) \ntest['Age'].fillna((test['Age'].mean()), inplace=True) \ntest['Fare'].fillna((test['Fare'].mean()), inplace=True) \ntrain['Embarked'].fillna('S', inplace=True)\ntrain.info()\ntest.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"s = (train.dtypes == 'object')\nobject_cols = list(s[s].index)\n\nfrom sklearn.preprocessing import OneHotEncoder\n\nOH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\nOH_cols_train = pd.DataFrame(OH_encoder.fit_transform(train[object_cols]))\nOH_cols_test = pd.DataFrame(OH_encoder.transform(test[object_cols]))\n\nOH_cols_train.index = train.index\nOH_cols_test.index = test.index\n\nnum_X_train = train.drop(object_cols, axis=1)\nnum_X_test = test.drop(object_cols, axis=1)\n\nOH_X_train = pd.concat([num_X_train, OH_cols_train], axis=1)\nOH_X_test= pd.concat([num_X_test, OH_cols_test], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sklearn.neighbors.KNeighborsClassifier\nsklearn.linear_model.LinearRegression\nsklearn.ensemble.RandomForestClassifier\nsklearn.ensemble.GradientBoostingClassifier\nxgb_model = xgb.XGBClassifier()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"training, valid, ytraining, yvalid = train_test_split(OH_X_train,y,test_size=0.5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model1=RandomForestClassifier()\nmodel2=XGBClassifier()\nmodel3=neighbors.KNeighborsClassifier()\nmodel4=GradientBoostingClassifier()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred1=model1.fit(training,ytraining)\npred2=model2.fit(training,ytraining)\npred3=model3.fit(training,ytraining)\npred4=model4.fit(training,ytraining)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred1=model1.predict(valid)\npred2=model2.predict(valid)\npred3=model3.predict(valid)\npred4=model4.predict(valid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_pred1=model1.predict(OH_X_test)\ntest_pred2=model2.predict(OH_X_test)\ntest_pred3=model3.predict(OH_X_test)\ntest_pred4=model4.predict(OH_X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stacked=np.column_stack((pred1,pred2,pred3,pred4))\nstacked_test_predictions=np.column_stack((test_pred1,test_pred2,test_pred3,test_pred4))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"meta_model=XGBClassifier()\nmeta_model.fit(stacked,yvalid)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final=meta_model.predict(stacked_test_predictions)\noutput = pd.DataFrame({'PassengerId': x, 'Survived': final})\noutput.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.read_csv('submission.csv')\nsubmission.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}